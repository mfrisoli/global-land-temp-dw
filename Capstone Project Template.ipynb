{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### WORLD CITIES LAND TEMPERATURE ETL & DATA WAREHOUSE\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import psycopg2\n",
    "from helpers.sql import sql_create_tables, staging_insert, sql_drop_tables, sql_insert_tables\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "directory = os.path.realpath(\"..\") + '/global-land-temp-dw/'\n",
    "tables = ['GlobalLandTemperaturesByMajorCity.csv', 'GlobalLandTemperaturesByCity.csv']\n",
    "\n",
    "df_major_city = pd.read_csv(directory + \"data/\" + tables[0])\n",
    "df_city = pd.read_csv(directory + \"data/\" + tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA values This data requires all values to be available\n",
    "\n",
    "def drop_na(pd_df):\n",
    "\n",
    "    print(f'Number of rows before removing NA: {pd_df.shape[0]:,}')\n",
    "\n",
    "    pd_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "    print(f'Number of rows after removing NA: {pd_df.shape[0]:,}')\n",
    "\n",
    "\n",
    "drop_na(df_major_city)\n",
    "drop_na(df_city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for Boolean Major city\n",
    "df_major_city = df_major_city.assign(major_city='true')\n",
    "df_city = df_city.assign(major_city='false')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatnate both datasets\n",
    "dframes = [df_major_city, df_city]\n",
    "df = pd.concat(dframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by year\n",
    "df.sort_values(by='dt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm Data types are as expected\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV to load into SQL redshift\n",
    "df.to_csv(directory + \"data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to s3 Function from AWS Services https://boto3.amazonaws.com/v1/documentation/api/1.10.46/guide/s3-uploading-files.html\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Bucket Name from configurations \n",
    "config = ConfigParser()\n",
    "config.read('DW.cfg')\n",
    "file_log = config.get('S3', 'log_data')\n",
    "\n",
    "upload_file(directory + \"data/dataset.csv\", file_log, \"logs/log_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "source": [
    "### Star Schema"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "source": [
    "# Get Database Variables\n",
    "config = ConfigParser()\n",
    "config.read('DW.cfg')\n",
    "\n",
    "print(\"{}, {}, {}, {}, {}\".format(*config['CLUSTER'].values()))\n",
    "\n",
    "\n",
    "# Connect to redshift database\n",
    "conn = psycopg2.connect(\"\"\"host={} \n",
    "                           dbname={} \n",
    "                           user={} \n",
    "                           password={}\n",
    "                           port={}\"\"\"\\\n",
    "                           .format(*config['CLUSTER'].values()    \n",
    "))\n",
    "\n",
    "# conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dwhcluster.cedlo7g6palf.eu-west-1.redshift.amazonaws.com, landtempdb, dwhuser, Passw0rd, 5439\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all table if exists\n",
    "for query in sql_drop_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "for query in sql_create_tables:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    COPY staging_events (\n        index,\n        dt,\n        AverageTemperature,\n        AverageTemperatureUncertainty,\n        City,\n        Country,\n        Latitude,\n        Longitude,\n        major_city\n    )\n    FROM  's3://global-land-temp/logs/'\n    CREDENTIALS 'aws_iam_role=arn:aws:iam::879294216748:role/dwhRole'\n    REGION 'eu-west-1'\n    DELIMITER ','\n    DATEFORMAT 'auto'\n    IGNOREHEADER 1\n    ;\n\n"
     ]
    }
   ],
   "source": [
    "# Copy data to Staging\n",
    "s3_bucket = \"s3://{}/logs/\".format(config.get('S3','log_data'))\n",
    "\n",
    "sql_query = staging_insert.format(\n",
    "    s3_bucket,\n",
    "    config.get('IAM_ROLE','ARN'),\n",
    "    config.get('CLUSTER','dwh_region')\n",
    "    )\n",
    "# print(sql_query)\n",
    "cur.execute(sql_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data from staging to facts and dimensions\n",
    "for query in sql_insert_tables:\n",
    "    # print(query)\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Connection to the DB\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def data_quality_check(cur, table):\n",
    "    \"\"\"\n",
    "    Function that check if table has rows\n",
    "\n",
    "    Argument:\n",
    "    cur: <object> Posgres connection cursor\n",
    "    table: <list> list of tables from the schema\n",
    "\n",
    "    returns None\n",
    "    \n",
    "    \"\"\"\n",
    "    sql_test = \"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM {}\n",
    "        LIMIT 10;\n",
    "        \"\"\".format(table)\n",
    "    try:\n",
    "        cur.execute(sql_test)\n",
    "        data_test = cur.fetchall()\n",
    "\n",
    "        if len(data_test) < 1:\n",
    "            raise ValueError(\"Table '{}' is empty\".format(table))\n",
    "\n",
    "        if data_test[0][0] < 1:\n",
    "            raise ValueError(\"Table '{}' has no rows\".format(table))\n",
    "\n",
    "        print('Data Quality SUCCESS for table: {}. Total rows: {}'\\\n",
    "                .format(table, data_test[0][0]))\n",
    "\n",
    "\n",
    "\n",
    "    except psycopg2.errors.UndefinedTable as e:\n",
    "        # Close Connection\n",
    "        conn.close()\n",
    "        raise Exception(e)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Quality SUCCESS for table: readings_by_city. Total rows: 8609236\nData Quality SUCCESS for table: cities. Total rows: 3610\nData Quality SUCCESS for table: time. Total rows: 3167\n"
     ]
    }
   ],
   "source": [
    "tables = ['readings_by_city', 'cities', 'time']\n",
    "\n",
    "for table in tables:\n",
    "\n",
    "    data_quality_check(cur, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = [\n",
    "    {   \n",
    "        'table':'Dimension cities',\n",
    "        'field name': 'city_id',\n",
    "        'data type': 'BIGINT IDENTITY(0,1)',\n",
    "        'data format': 'NNNNNNN',\n",
    "        'field size': 'VARIABLE',\n",
    "        'description':'Primary Key Index number for each row',\n",
    "        'example':'03'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension cities',\n",
    "        'field name': 'city',\n",
    "        'data type': 'TEXT',\n",
    "        'data format': '',\n",
    "        'field size': 'VARIABLE',\n",
    "        'description':'city name, comes from staging_events',\n",
    "        'example':'Barcelona'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension cities',\n",
    "        'field name': 'country',\n",
    "        'data type': 'TEXT',\n",
    "        'data format': '',\n",
    "        'field size': 'VARIABLE',\n",
    "        'description':'country name, comes from staging_events',\n",
    "        'example':'Venezuela'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension cities',\n",
    "        'field name': 'latitude',\n",
    "        'data type': 'TEXT',\n",
    "        'data format': 'NN.NT',\n",
    "        'field size': 'VARIABLE',\n",
    "        'description':'city latitude, comes from staging_events',\n",
    "        'example':'12.5N'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension cities',\n",
    "        'field name': 'longitude',\n",
    "        'data type': 'TEXT',\n",
    "        'data format': 'NN.NT',\n",
    "        'field size': 'VARIABLE',\n",
    "        'description':'city longitude, comes from staging_events',\n",
    "        'example':'12.5E'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension cities',\n",
    "        'field name': 'major_city',\n",
    "        'data type': 'BOOLEAN',\n",
    "        'data format': 'true/false',\n",
    "        'field size': '5',\n",
    "        'description':'Boolean that identifies if city is major or not from staging_events',\n",
    "        'example':'true'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension time',\n",
    "        'field name': 'dt',\n",
    "        'data type': 'DATE',\n",
    "        'data format': 'YYYY-MM-DD',\n",
    "        'field size': '10',\n",
    "        'description':'date of temperature measure, comes from staging_events',\n",
    "        'example':'2018-02-07'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension time',\n",
    "        'field name': 'day',\n",
    "        'data type': 'SMALLINT',\n",
    "        'data format': 'NN',\n",
    "        'field size': '2',\n",
    "        'description':'day of temperature measure, comes from column dt',\n",
    "        'example':'07'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension time',\n",
    "        'field name': 'month',\n",
    "        'data type': 'SMALLINT',\n",
    "        'data format': 'NN',\n",
    "        'field size': '2',\n",
    "        'description':'month of temperature measure, comes from column dt',\n",
    "        'example':'02'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension time',\n",
    "        'field name': 'week',\n",
    "        'data type': 'SMALLINT',\n",
    "        'data format': 'NN',\n",
    "        'field size': '2',\n",
    "        'description':'week of temperature measure, comes from column dt',\n",
    "        'example':'02'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension time',\n",
    "        'field name': 'weekday',\n",
    "        'data type': 'SMALLINT',\n",
    "        'data format': 'NN',\n",
    "        'field size': '2',\n",
    "        'description':'week day number of temperature measure, comes from column dt',\n",
    "        'example':'02'\n",
    "    },\n",
    "    {\n",
    "        'table':'Dimension time',\n",
    "        'field name': 'year',\n",
    "        'data type': 'SMALLINT',\n",
    "        'data format': 'NNNN',\n",
    "        'field size': '4',\n",
    "        'description':'year of temperature measure, comes from column dt',\n",
    "        'example':'2018'\n",
    "    },\n",
    "    {\n",
    "        'table':'Fact readings_by_city',\n",
    "        'field name': 'by_city_id',\n",
    "        'data type': 'BIGINT IDENTITY(0,1)',\n",
    "        'data format': 'NNNNNN',\n",
    "        'field size': 'VARIABLE',\n",
    "        'description':'Primary Key Index number for each row',\n",
    "        'example':'2'\n",
    "    },\n",
    "    {\n",
    "        'table':'Fact readings_by_city',\n",
    "        'field name': 'city_id',\n",
    "        'data type': 'NUMERIC',\n",
    "        'data format': 'NNNNNN',\n",
    "        'field size': 'VARIABLE',\n",
    "        'description':'Foreign Key Index number from cities table',\n",
    "        'example':'4525'\n",
    "    },\n",
    "    {\n",
    "        'table':'Fact readings_by_city',\n",
    "        'field name': 'avg_temp',\n",
    "        'data type': 'NUMERIC(7,3)',\n",
    "        'data format': 'NNNN.NNN',\n",
    "        'field size': '7',\n",
    "        'description':'temperature reading comes from staging_events',\n",
    "        'example':'25.025'\n",
    "    },\n",
    "    {\n",
    "        'table':'Fact readings_by_city',\n",
    "        'field name': 'avg_temp_uncertainty',\n",
    "        'data type': 'NUMERIC(7,3)',\n",
    "        'data format': 'NNNN.NNN',\n",
    "        'field size': '7',\n",
    "        'description':'temperature uncertainty reading comes from staging_events',\n",
    "        'example':'1.025'\n",
    "    },\n",
    "    {\n",
    "        'table':'Fact readings_by_city',\n",
    "        'field name': 'date',\n",
    "        'data type': 'DATE',\n",
    "        'data format': 'YYYY-MM-DD',\n",
    "        'field size': '7',\n",
    "        'description':'date of temperature measure, comes from staging_events',\n",
    "        'example':'2018-02-07'\n",
    "    },\n",
    "    {\n",
    "        'table':'Fact readings_by_city',\n",
    "        'field name': 'major_city',\n",
    "        'data type': 'BOLEAN',\n",
    "        'data format': '',\n",
    "        'field size': '5',\n",
    "        'description':'Boolean that identifies if city is major or not from staging_events',\n",
    "        'example':'true'\n",
    "    },\n",
    "    \n",
    "    \n",
    "       \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    table            field name             data type  \\\n",
       "0        Dimension cities               city_id  BIGINT IDENTITY(0,1)   \n",
       "1        Dimension cities                  city                  TEXT   \n",
       "2        Dimension cities               country                  TEXT   \n",
       "3        Dimension cities              latitude                  TEXT   \n",
       "4        Dimension cities             longitude                  TEXT   \n",
       "5        Dimension cities            major_city               BOOLEAN   \n",
       "6          Dimension time                    dt                  DATE   \n",
       "7          Dimension time                   day              SMALLINT   \n",
       "8          Dimension time                 month              SMALLINT   \n",
       "9          Dimension time                  week              SMALLINT   \n",
       "10         Dimension time               weekday              SMALLINT   \n",
       "11         Dimension time                  year              SMALLINT   \n",
       "12  Fact readings_by_city            by_city_id  BIGINT IDENTITY(0,1)   \n",
       "13  Fact readings_by_city               city_id               NUMERIC   \n",
       "14  Fact readings_by_city              avg_temp          NUMERIC(7,3)   \n",
       "15  Fact readings_by_city  avg_temp_uncertainty          NUMERIC(7,3)   \n",
       "16  Fact readings_by_city                  date                  DATE   \n",
       "17  Fact readings_by_city            major_city                BOLEAN   \n",
       "\n",
       "   data format field size                                        description  \\\n",
       "0      NNNNNNN   VARIABLE              Primary Key Index number for each row   \n",
       "1                VARIABLE               city name, comes from staging_events   \n",
       "2                VARIABLE            country name, comes from staging_events   \n",
       "3        NN.NT   VARIABLE           city latitude, comes from staging_events   \n",
       "4        NN.NT   VARIABLE          city longitude, comes from staging_events   \n",
       "5   true/false          5  Boolean that identifies if city is major or no...   \n",
       "6   YYYY-MM-DD         10  date of temperature measure, comes from stagin...   \n",
       "7           NN          2   day of temperature measure, comes from column dt   \n",
       "8           NN          2  month of temperature measure, comes from colum...   \n",
       "9           NN          2  week of temperature measure, comes from column dt   \n",
       "10          NN          2  week day number of temperature measure, comes ...   \n",
       "11        NNNN          4  year of temperature measure, comes from column dt   \n",
       "12      NNNNNN   VARIABLE              Primary Key Index number for each row   \n",
       "13      NNNNNN   VARIABLE         Foreign Key Index number from cities table   \n",
       "14    NNNN.NNN          7      temperature reading comes from staging_events   \n",
       "15    NNNN.NNN          7  temperature uncertainty reading comes from sta...   \n",
       "16  YYYY-MM-DD          7  date of temperature measure, comes from stagin...   \n",
       "17                      5  Boolean that identifies if city is major or no...   \n",
       "\n",
       "       example  \n",
       "0           03  \n",
       "1    Barcelona  \n",
       "2    Venezuela  \n",
       "3        12.5N  \n",
       "4        12.5E  \n",
       "5         true  \n",
       "6   2018-02-07  \n",
       "7           07  \n",
       "8           02  \n",
       "9           02  \n",
       "10          02  \n",
       "11        2018  \n",
       "12           2  \n",
       "13        4525  \n",
       "14      25.025  \n",
       "15       1.025  \n",
       "16  2018-02-07  \n",
       "17        true  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>table</th>\n      <th>field name</th>\n      <th>data type</th>\n      <th>data format</th>\n      <th>field size</th>\n      <th>description</th>\n      <th>example</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dimension cities</td>\n      <td>city_id</td>\n      <td>BIGINT IDENTITY(0,1)</td>\n      <td>NNNNNNN</td>\n      <td>VARIABLE</td>\n      <td>Primary Key Index number for each row</td>\n      <td>03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dimension cities</td>\n      <td>city</td>\n      <td>TEXT</td>\n      <td></td>\n      <td>VARIABLE</td>\n      <td>city name, comes from staging_events</td>\n      <td>Barcelona</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dimension cities</td>\n      <td>country</td>\n      <td>TEXT</td>\n      <td></td>\n      <td>VARIABLE</td>\n      <td>country name, comes from staging_events</td>\n      <td>Venezuela</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dimension cities</td>\n      <td>latitude</td>\n      <td>TEXT</td>\n      <td>NN.NT</td>\n      <td>VARIABLE</td>\n      <td>city latitude, comes from staging_events</td>\n      <td>12.5N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dimension cities</td>\n      <td>longitude</td>\n      <td>TEXT</td>\n      <td>NN.NT</td>\n      <td>VARIABLE</td>\n      <td>city longitude, comes from staging_events</td>\n      <td>12.5E</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Dimension cities</td>\n      <td>major_city</td>\n      <td>BOOLEAN</td>\n      <td>true/false</td>\n      <td>5</td>\n      <td>Boolean that identifies if city is major or no...</td>\n      <td>true</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Dimension time</td>\n      <td>dt</td>\n      <td>DATE</td>\n      <td>YYYY-MM-DD</td>\n      <td>10</td>\n      <td>date of temperature measure, comes from stagin...</td>\n      <td>2018-02-07</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Dimension time</td>\n      <td>day</td>\n      <td>SMALLINT</td>\n      <td>NN</td>\n      <td>2</td>\n      <td>day of temperature measure, comes from column dt</td>\n      <td>07</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Dimension time</td>\n      <td>month</td>\n      <td>SMALLINT</td>\n      <td>NN</td>\n      <td>2</td>\n      <td>month of temperature measure, comes from colum...</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Dimension time</td>\n      <td>week</td>\n      <td>SMALLINT</td>\n      <td>NN</td>\n      <td>2</td>\n      <td>week of temperature measure, comes from column dt</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Dimension time</td>\n      <td>weekday</td>\n      <td>SMALLINT</td>\n      <td>NN</td>\n      <td>2</td>\n      <td>week day number of temperature measure, comes ...</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Dimension time</td>\n      <td>year</td>\n      <td>SMALLINT</td>\n      <td>NNNN</td>\n      <td>4</td>\n      <td>year of temperature measure, comes from column dt</td>\n      <td>2018</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Fact readings_by_city</td>\n      <td>by_city_id</td>\n      <td>BIGINT IDENTITY(0,1)</td>\n      <td>NNNNNN</td>\n      <td>VARIABLE</td>\n      <td>Primary Key Index number for each row</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Fact readings_by_city</td>\n      <td>city_id</td>\n      <td>NUMERIC</td>\n      <td>NNNNNN</td>\n      <td>VARIABLE</td>\n      <td>Foreign Key Index number from cities table</td>\n      <td>4525</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Fact readings_by_city</td>\n      <td>avg_temp</td>\n      <td>NUMERIC(7,3)</td>\n      <td>NNNN.NNN</td>\n      <td>7</td>\n      <td>temperature reading comes from staging_events</td>\n      <td>25.025</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Fact readings_by_city</td>\n      <td>avg_temp_uncertainty</td>\n      <td>NUMERIC(7,3)</td>\n      <td>NNNN.NNN</td>\n      <td>7</td>\n      <td>temperature uncertainty reading comes from sta...</td>\n      <td>1.025</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Fact readings_by_city</td>\n      <td>date</td>\n      <td>DATE</td>\n      <td>YYYY-MM-DD</td>\n      <td>7</td>\n      <td>date of temperature measure, comes from stagin...</td>\n      <td>2018-02-07</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Fact readings_by_city</td>\n      <td>major_city</td>\n      <td>BOLEAN</td>\n      <td></td>\n      <td>5</td>\n      <td>Boolean that identifies if city is major or no...</td>\n      <td>true</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "data_dic_df = pd.DataFrame(data_dictionary)\n",
    "\n",
    "data_dic_df.to_csv(directory+\"data_dict.csv\")\n",
    "\n",
    "data_dic_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}